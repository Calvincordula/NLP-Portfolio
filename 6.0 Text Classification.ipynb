{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e8266c-1e93-4212-b741-ffdb0c82b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9851a94-88bc-4651-9135-f400246adc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([(\"i love spending time with my friends and family\", \"positive\"),\n",
    "(\"that was the best meal i've ever had in my life\", \"positive\"),\n",
    "(\"i feel so grateful for everything i have in my life\", \"positive\"),\n",
    "(\"i received a promotion at work and i couldn't be happier\", \"positive\"),\n",
    "(\"watching a beautiful sunset always fills me with joy\", \"positive\"),\n",
    "(\"my partner surprised me with a thoughtful gift and it made my day\", \"positive\"),\n",
    "(\"i am so proud of my daughter for graduating with honors\", \"positive\"),\n",
    "(\"listening to my favorite music always puts me in a good mood\", \"positive\"),\n",
    "(\"i love the feeling of accomplishment after completing a challenging task\", \"positive\"),\n",
    "(\"i am excited to go on vacation next week\", \"positive\"),\n",
    "(\"i feel so overwhelmed with work and responsibilities\", \"negative\"),\n",
    "(\"the traffic during my commute is always so frustrating\", \"negative\"),\n",
    "(\"i received a parking ticket and it ruined my day\", \"negative\"),\n",
    "(\"i got into an argument with my partner and we're not speaking\", \"negative\"),\n",
    "(\"i have a headache and i feel terrible\", \"negative\"),\n",
    "(\"i received a rejection letter for the job i really wanted\", \"negative\"),\n",
    "(\"my car broke down and it's going to be expensive to fix\", \"negative\"),\n",
    "(\"i'm feeling sad because i miss my friends who live far away\", \"negative\"),\n",
    "(\"i'm frustrated because i can't seem to make progress on my project\", \"negative\"),\n",
    "(\"i'm disappointed because my team lost the game\", \"negative\")],\n",
    "                    columns= ['text', 'sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d74681-b3ab-42c3-89f8-7dc2a1ed42f7",
   "metadata": {},
   "source": [
    "#### Shuffling our data and re-setting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e7a461-8281-41a7-af21-27a21dc6e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d3ebb-c00a-4f2c-b6f4-ce177df4c836",
   "metadata": {},
   "source": [
    "#### We now prepare the inputs for our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f72048-c520-42ce-b1c2-eb69abde5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['text']\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f678c98b-1dd3-449a-bee0-cb7e3035fefa",
   "metadata": {},
   "source": [
    "#### Vectorizing our text\n",
    "We use the BoW approach with the CountVectorizer function- converting text data into BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5bed095-becd-4b73-8ebe-68afbebac4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "469bb828-21db-4751-b725-2e4bb524b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec_fit = count_vec.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7c63f3-023d-4faa-814f-d587f6e87c51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m bag_of_words = \u001b[43mpd\u001b[49m.DataFrame(count_vec_fit.toarray(), columns = count_vec.get_feature_names_out())\n\u001b[32m      2\u001b[39m bag_of_words\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "bag_of_words = pd.DataFrame(count_vec_fit.toarray(), columns = count_vec.get_feature_names_out())\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b115eb1-0047-48ed-bacc-ef42034a7815",
   "metadata": {},
   "source": [
    "#### Splitting our data into training and testing sets\n",
    "We want to ensure we have the same train and test split each time we run the code hence the 'random_state()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77e002de-19c3-46a4-bb4f-01568f185ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(bag_of_words, y, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00558a64-c349-451e-a52a-cfb8f6d8531c",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "We now train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0463b278-e59a-44b3-8f39-0c89ee563e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b03fa4-58cf-4c3c-9b61-f057471050da",
   "metadata": {},
   "source": [
    "#### We now generate prediction to see how the model generalizes with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bf519a4-7a76-4869-80ec-00d7777f4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c579a4a-d36d-439a-a4a3-c87ebcc9ed96",
   "metadata": {},
   "source": [
    "#### We now measure model performance- accuracy\n",
    "We compare true labels with predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b3cd7e-27fa-476c-8d43-8501127566fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a4645-fdb0-423e-aace-7fb193726875",
   "metadata": {},
   "source": [
    "#### Classification report \n",
    "We want a more detailed information on the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "350f2b7f-a482-4660-a944-f93b66fdeb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      1.00      0.29         1\n",
      "    positive       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.17         6\n",
      "   macro avg       0.08      0.50      0.14         6\n",
      "weighted avg       0.03      0.17      0.05         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_lr, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ddf90-2967-4762-a8a0-4ad8e17c2274",
   "metadata": {},
   "source": [
    "##### precision: out of all the sentences predicted by the model as + or -, which one was actually correct?, \n",
    "##### recall: out of all the sentences that are truly + or -, what proportion did the model correctly find?\n",
    "##### f1-score: a number (from 0-1) that combines precision and recall into one measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f60648-81c4-4c5d-8569-82e0fdbd0e6d",
   "metadata": {},
   "source": [
    "### The Naive-Bayes classifier \n",
    "We want to improve the low accuracy score obtained. NB classifier works using probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ee5be3-c54c-442b-8c79-b95b6079dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ca593a3-6490-4f4a-b58a-cdd4a2b0836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dfbdd89-6388-4fde-a233-e1649bfb490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cac730c8-ebf6-4a41-8dea-59fd024ffc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_nb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c17bc2a8-8861-4ea0-84c1-50261137687f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         1\n",
      "    positive       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.33      0.20      0.25         6\n",
      "weighted avg       0.56      0.33      0.42         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_nb, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1ab744-3e07-4c29-93bc-a20cad3acf56",
   "metadata": {},
   "source": [
    "The Naive-Bayes model gives a better prediction but there's still room for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d9fa2-deb3-44cc-8ef3-a88dafbe472d",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine\n",
    "We want to improve the accuracy further. LSVM helps to find the best possible boundary that separates the boundaries (+&-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae73a2e6-3b15-4712-a6ee-de8a3b3f9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a25027f-8388-4e65-8b96-557a4afb468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SGDClassifier().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0d47955-05d0-4db9-aa3a-6f04c389f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1bf50ac-938c-4988-b796-6eb7073df7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_svm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235b0c9f-469c-49dc-a298-337808808984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.17      1.00      0.29         1\n",
      "    positive       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.17         6\n",
      "   macro avg       0.08      0.50      0.14         6\n",
      "weighted avg       0.03      0.17      0.05         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svm, zero_division = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e7cc8-918f-4db7-87c4-4ab83c9c8aed",
   "metadata": {},
   "source": [
    "We haven't seen any much improvement either. It's either we clean our data further or add more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b727a4-c501-4ff7-9b9a-48f8f4b75171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
